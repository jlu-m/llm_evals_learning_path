{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lm_eval"
      ],
      "metadata": {
        "id": "b_LHKIev9gWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlYgrMNs9VG1"
      },
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=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\n",
        "!mkdir -p results\n",
        "!python -m lm_eval \\\n",
        "  --model openai-chat-completions \\\n",
        "  --model_args model=gpt-4o,temperature=0 \\\n",
        "  --tasks truthfulqa_gen \\\n",
        "  --limit 100 \\\n",
        "  --seed 42 \\\n",
        "  --output_path results/gpt4o_truthfulqa_sampled.json \\\n",
        "  --write_out \\\n",
        "  --log_samples \\\n",
        "  --apply_chat_template \\\n",
        "  --verbosity INFO"
      ]
    }
  ]
}